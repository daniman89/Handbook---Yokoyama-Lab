layout: default
title: "IV Dry Lab Best Practices"
---
# IV. Dry Lab Best Practices

[Home](index.md)  

## Table of Contents
- [About The Yokoyama Lab](I_About_The_Yokoyama_Lab.md)
- [People](II_People.md)
- [General Policies and Expectations](III_General_Policies_and_Expectations.md)

# IV. Dry Lab Best Practices

## A. Projects

### a) General expectations

#### i. Reproducibility 
All analyses should be documented well enough that another lab member can take your project from input data → output data and replicate the same results with minimal effort. This includes creating bioinformatics software pipelines, or generalizable scripts with comprehensive documentation, as well as scientific motivation/ biological relevance of your analysis.

#### ii. Transparency
All aspects of a dry lab project should be documented, including environmental set-up, data manipulation steps, statistical analyses. Potential roadblocks and alternative data analysis routes throughout your project, should also be saved and noted as these could facilitate redundant troubleshooting in the future.

#### iii. Timely Updates
Do not wait until the end of a project to write your documentation. Collaborators may need to jump into a project at any time - continuously document your project from start to finish. 
The Yokoyama Lab expects all members to push updates to their analysis plan, code at least once per week.

### b) Before starting a new project

#### 1.1. Create a new repository using the Yokoyama Template Repo  
[https://github.com/YOKOYAMA-UCSF/template_repo/tree/main](https://github.com/YOKOYAMA-UCSF/template_repo/tree/main)  
Tutorial on working with Git and Github:

#### 1.2. Clone the repository into /yokoyama/seqdata/projects  
Review the following tutorial on the Yokoyama Lab github workflow for more information: [INSERT LINK]  
If you are working on a sub-project that began as a separate repository, consider forking the original repository.  

#### 1.3. Modify the template README within the repository. This requires you to define:  
- Project Title  
- Project Aims  
- Background/Overview  
- Data Structure  
- Analysis Plan  
As you develop and upload specific scripts, you would link them under this section and define the purpose, outcome of each script.  
- Expected Results  
- Acknowledgements  

#### 1.4. During project set-up, be sure to document:  
- The location, structure of input (raw, original) datasets.  
- The steps required to set up the project environment, including software dependencies, operating system, computational/ hardware requirements.

### c) During a project

#### 1.1. Push updates to your project’s repo at minimum once per week. This includes updates to the analysis plan, code changes, etc. Document any major changes.  
Consider pushing to Github at the end of the day to save intermediate files/progress.

#### 1.2. Document any data manipulation or data pre-processing that is required to prepare the original data for the planned analyses.

#### 1.3. Write generalizable code. This means:  
- Avoid hardcoding file names, paths, sample IDs, etc. Depending on your workflow, you may write a CONFIG file, or a txt file that you pass in as input to your script that contains your file names.  
- If possible, write modular functions that can be re-used by others.  

#### 1.4. Write well-commented code.  
- When starting a new script, define the script author, title the script, and provide a description of the goals of the script.  
- Annotate each new variable defined, when data is imported.  
- If using a markdown/jupyter notebook, define the purpose of each code chunk.  
- Clearly document the format of input data required, and the expected output, of any custom code.  

### d) Finalizing a project

#### 1. Document the final location of output files generated by your project.  
#### 2. Describe the final results of the analyses and possible future directions if any.  
#### 3. Consider that all analyses performed in the dry lab may be included in a future publication. Ensure your Github repo is sufficiently documented such that it can be made public and shared outside of the lab if needed.  
- i. The original copy of the repo will be archived for internal purposes  
- ii. Plan to develop a second, public repo with all internal data redacted (e.g. direct path names, server information, participant data, etc.)

#### 4. Before publication, ensure that you remove any private data from your repo, including:  
- i. PIDNs  
- ii. Participant metadata  
- iii. IP addresses  
- iv. Hardcoded file paths

#### 5. Ideally, test your code in a different environment (new VM, try it out on Wynton, etc).

## B. Dry Lab Data Storage, Management & Sharing

Our primary data storage server is located in /yokoyama/seqdata, referred to as “seqdata”.

├── archive
├── data
│      └── example_dataset
│              ├── source # original data 
│              ├── processed # data that has been processed in any way (can have subfolders)
│              ├── docs
│              ├── LICENSE.md
│              └── README.md
├── projects
│      └── example_project
├── .GITIGNORE
├── README.md
│   	├── data (this should be a soft link to files located in the data directory.)
│   	├── resources
│   	├── results
│   	└── scripts
                        └── configs
└── tools
            │—- Gene Query

How to decide whether your task is a tool or a project?

- If the aspects of this task are something we can build on, then it is a Project.  
- If the aspects of this task are reusable, then it is a tool.  

- Reorganization of archival projects seqdata is ongoing.  
- Raw data (downloaded from the internet, transferred from collaborators, raw data generated from the lab) will live in /yokoyama/seqdata/data.  
- New project repositories will be cloned from Github into /yokoyama/seqdata/projects.  
- Shared tools or resources will be kept in a shared /yokoyama/seqdata/tools.  
- We expect that raw data will be placed in /yokoyama/seqdata/data and documented accordingly.  
    - At minimum, you should write a README that describes:
        - Data Downloader: who downloaded the data on what date (e.g., “Downloaded by Alexis Oddi on 01/01/2024”)  
        - Version: What version of the dataset did you download, if multiple?  
        - Source: The source of the original dataset (link to a data repository, publication, direct link, or other description)  
        - Methods that describe data generation, if available. This may be provided alongside the downloaded dataset; otherwise can link to publication.  
        - Supporting documentation should be downloaded alongside the raw data, including a data dictionary and README provided by the data generator.  
- Soft link files from/yokoyama/seqdata/data into your project directory within /yokoyama/seqdata/projects. See this tutorial on how to soft link files in Linux.  
- Use clear and consistent naming conventions when creating new files. Here is a helpful worksheet from CalTech.  
    - Regardless of how you name files, ensure that the files are appropriately annotated in your repository. Use the template tree structure in your README in order to write comments about the contents of each file.  
- Within each project directory, write a configuration file in order to define and save the input/output directory paths and files specific to your project. The config file needs to be loaded into each new script in order to access the saved values. See more details here.  


